{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import numpy as np\n",
    "from metalearner import Meta\n",
    "from omniglot import OmniglotNShot\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(222)\n",
    "torch.cuda.manual_seed_all(222)\n",
    "np.random.seed(222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Args(epoch=40000, n_way=5, k_spt=1, k_qry=15, imgsz=28, imgc=1, task_num=32, meta_lr=0.001, update_lr=0.4, update_step=5, update_step_test=10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    epoch: int=40000\n",
    "    n_way: int=5\n",
    "    k_spt: int=1\n",
    "    k_qry: int=15\n",
    "    imgsz: int=28\n",
    "    imgc: int=1\n",
    "    task_num: int=32\n",
    "    meta_lr: float=1e-3\n",
    "    update_lr: float=0.4\n",
    "    update_step: int=5\n",
    "    update_step_test: int=10\n",
    "\n",
    "args = Args()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [\n",
    "    ('conv2d', [64, 1, 3, 3, 2, 0]),\n",
    "    ('relu', [True]),\n",
    "    ('bn', [64]),\n",
    "    ('conv2d', [64, 64, 3, 3, 2, 0]),\n",
    "    ('relu', [True]),\n",
    "    ('bn', [64]),\n",
    "    ('conv2d', [64, 64, 3, 3, 2, 0]),\n",
    "    ('relu', [True]),\n",
    "    ('bn', [64]),\n",
    "    ('conv2d', [64, 64, 2, 2, 1, 0]),\n",
    "    ('relu', [True]),\n",
    "    ('bn', [64]),\n",
    "    ('flatten', []),\n",
    "    ('linear', [args.n_way, 64])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "maml = Meta(args, config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta(\n",
      "  (net): Learner(\n",
      "    conv2d:(ch_in:1, ch_out:64, k:3x3, stride:2, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(64,)\n",
      "    conv2d:(ch_in:64, ch_out:64, k:3x3, stride:2, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(64,)\n",
      "    conv2d:(ch_in:64, ch_out:64, k:3x3, stride:2, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(64,)\n",
      "    conv2d:(ch_in:64, ch_out:64, k:2x2, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(64,)\n",
      "    flatten:()\n",
      "    linear:(in:64, out:5)\n",
      "    \n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.cuda.FloatTensor of size 64x1x3x3 (GPU 0)]\n",
      "        (1): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (2): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (3): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (4): Parameter containing: [torch.cuda.FloatTensor of size 64x64x3x3 (GPU 0)]\n",
      "        (5): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (6): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (7): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (8): Parameter containing: [torch.cuda.FloatTensor of size 64x64x3x3 (GPU 0)]\n",
      "        (9): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (10): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (11): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (12): Parameter containing: [torch.cuda.FloatTensor of size 64x64x2x2 (GPU 0)]\n",
      "        (13): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (14): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (15): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (16): Parameter containing: [torch.cuda.FloatTensor of size 5x64 (GPU 0)]\n",
      "        (17): Parameter containing: [torch.cuda.FloatTensor of size 5 (GPU 0)]\n",
      "    )\n",
      "    (vars_bn): ParameterList(\n",
      "        (0): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (1): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (2): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (3): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (4): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (5): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (6): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "        (7): Parameter containing: [torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 91781\n"
     ]
    }
   ],
   "source": [
    "tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "print(maml)\n",
    "print('Total trainable tensors:', num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from omniglot.npy.\n",
      "DB: train (1200, 20, 1, 28, 28) test (423, 20, 1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<omniglot.OmniglotNShot at 0x2af4d0df2b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_train = OmniglotNShot('omniglot',\n",
    "                   batchsz=args.task_num,\n",
    "                   n_way=args.n_way,\n",
    "                   k_shot=args.k_spt,\n",
    "                   k_query=args.k_qry,\n",
    "                   imgsz=args.imgsz)\n",
    "db_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 \ttraining acc: 22.21%, 34.04%, 42.79%, 43.54%, 43.71%, 43.79%\n",
      "Test acc: [0.2008 0.3093 0.3936 0.4053 0.4067 0.4077 0.4087 0.4092 0.4094 0.41\n",
      " 0.4102]\n",
      "step: 50 \ttraining acc: 19.38%, 57.46%, 63.08%, 63.33%, 63.54%, 63.67%\n",
      "step: 100 \ttraining acc: 17.92%, 67.92%, 72.21%, 72.96%, 73.00%, 72.96%\n",
      "step: 150 \ttraining acc: 18.79%, 75.00%, 77.21%, 77.38%, 77.33%, 77.21%\n",
      "step: 200 \ttraining acc: 17.67%, 81.46%, 82.79%, 82.88%, 82.83%, 82.88%\n",
      "step: 250 \ttraining acc: 22.08%, 81.88%, 84.54%, 84.79%, 84.92%, 84.79%\n",
      "step: 300 \ttraining acc: 19.54%, 86.29%, 88.29%, 88.25%, 88.17%, 88.25%\n",
      "step: 350 \ttraining acc: 25.04%, 85.75%, 86.50%, 86.62%, 86.62%, 86.88%\n",
      "step: 400 \ttraining acc: 22.12%, 90.62%, 91.88%, 92.00%, 92.04%, 92.12%\n",
      "step: 450 \ttraining acc: 21.21%, 88.21%, 89.71%, 89.88%, 90.08%, 90.00%\n",
      "step: 500 \ttraining acc: 20.67%, 88.04%, 91.17%, 91.25%, 91.33%, 91.62%\n",
      "Test acc: [0.2036 0.8325 0.848  0.85   0.851  0.852  0.8525 0.853  0.8535 0.8535\n",
      " 0.854 ]\n",
      "step: 550 \ttraining acc: 16.75%, 90.38%, 91.54%, 91.83%, 91.92%, 92.00%\n",
      "step: 600 \ttraining acc: 21.00%, 88.75%, 89.79%, 89.92%, 89.92%, 90.08%\n",
      "step: 650 \ttraining acc: 19.38%, 89.58%, 91.83%, 91.83%, 91.83%, 91.96%\n",
      "step: 700 \ttraining acc: 19.42%, 90.33%, 91.38%, 92.04%, 92.00%, 92.04%\n",
      "step: 750 \ttraining acc: 19.92%, 88.88%, 90.33%, 91.04%, 91.21%, 91.25%\n",
      "step: 800 \ttraining acc: 21.12%, 94.00%, 95.58%, 95.79%, 95.88%, 95.88%\n",
      "step: 850 \ttraining acc: 21.96%, 90.04%, 92.92%, 93.08%, 93.17%, 93.21%\n",
      "step: 900 \ttraining acc: 20.79%, 90.17%, 92.46%, 92.62%, 92.67%, 92.71%\n",
      "step: 950 \ttraining acc: 19.12%, 92.96%, 94.25%, 94.33%, 94.38%, 94.33%\n",
      "step: 1000 \ttraining acc: 15.42%, 92.21%, 94.25%, 94.33%, 94.29%, 94.33%\n",
      "Test acc: [0.1987 0.8555 0.88   0.8823 0.884  0.885  0.8853 0.8857 0.886  0.8867\n",
      " 0.8867]\n",
      "step: 1050 \ttraining acc: 19.62%, 90.21%, 92.58%, 92.83%, 92.92%, 92.88%\n",
      "step: 1100 \ttraining acc: 22.92%, 90.21%, 93.12%, 93.71%, 93.92%, 93.92%\n",
      "step: 1150 \ttraining acc: 22.33%, 90.92%, 93.38%, 93.62%, 93.62%, 93.62%\n",
      "step: 1200 \ttraining acc: 20.92%, 92.54%, 92.67%, 93.67%, 93.75%, 93.92%\n",
      "step: 1250 \ttraining acc: 21.50%, 90.79%, 92.38%, 92.50%, 92.58%, 92.62%\n",
      "step: 1300 \ttraining acc: 22.96%, 91.67%, 93.58%, 93.75%, 93.88%, 94.00%\n",
      "step: 1350 \ttraining acc: 21.58%, 92.08%, 94.50%, 95.04%, 95.17%, 95.21%\n",
      "step: 1400 \ttraining acc: 20.46%, 91.71%, 93.58%, 93.71%, 93.71%, 93.79%\n",
      "step: 1450 \ttraining acc: 20.08%, 90.58%, 91.83%, 92.29%, 92.46%, 92.46%\n",
      "step: 1500 \ttraining acc: 23.42%, 89.88%, 93.04%, 93.08%, 93.25%, 93.25%\n",
      "Test acc: [0.2026 0.8584 0.884  0.887  0.888  0.8887 0.889  0.8896 0.89   0.8906\n",
      " 0.891 ]\n",
      "step: 1550 \ttraining acc: 23.50%, 92.08%, 94.38%, 94.33%, 94.46%, 94.58%\n",
      "step: 1600 \ttraining acc: 20.96%, 92.88%, 94.58%, 94.67%, 94.83%, 94.88%\n",
      "step: 1650 \ttraining acc: 17.92%, 92.71%, 94.04%, 94.08%, 94.17%, 94.12%\n",
      "step: 1700 \ttraining acc: 19.00%, 89.79%, 91.71%, 92.29%, 92.46%, 92.58%\n",
      "step: 1750 \ttraining acc: 23.79%, 89.92%, 92.58%, 92.92%, 93.04%, 93.12%\n",
      "step: 1800 \ttraining acc: 21.33%, 91.17%, 94.79%, 95.00%, 95.12%, 95.17%\n",
      "step: 1850 \ttraining acc: 17.21%, 92.71%, 95.08%, 95.62%, 95.62%, 95.71%\n",
      "step: 1900 \ttraining acc: 15.62%, 93.04%, 95.08%, 95.21%, 95.25%, 95.29%\n",
      "step: 1950 \ttraining acc: 21.50%, 92.29%, 94.33%, 94.46%, 94.54%, 94.54%\n",
      "step: 2000 \ttraining acc: 21.38%, 88.58%, 93.58%, 93.58%, 93.58%, 93.67%\n",
      "Test acc: [0.1985 0.863  0.889  0.892  0.893  0.8936 0.894  0.8945 0.8945 0.895\n",
      " 0.895 ]\n",
      "step: 2050 \ttraining acc: 20.12%, 91.96%, 94.33%, 94.67%, 94.58%, 94.54%\n",
      "step: 2100 \ttraining acc: 22.75%, 91.67%, 93.50%, 94.17%, 94.12%, 94.17%\n",
      "step: 2150 \ttraining acc: 18.12%, 94.33%, 96.17%, 96.25%, 96.33%, 96.33%\n",
      "step: 2200 \ttraining acc: 19.29%, 92.21%, 94.29%, 94.33%, 94.38%, 94.42%\n",
      "step: 2250 \ttraining acc: 22.29%, 92.08%, 94.58%, 94.67%, 94.71%, 94.75%\n",
      "step: 2300 \ttraining acc: 24.17%, 90.96%, 93.92%, 94.29%, 94.29%, 94.33%\n",
      "step: 2350 \ttraining acc: 20.00%, 93.50%, 95.29%, 95.38%, 95.42%, 95.50%\n",
      "step: 2400 \ttraining acc: 16.00%, 90.96%, 94.12%, 94.33%, 94.38%, 94.46%\n",
      "step: 2450 \ttraining acc: 19.33%, 91.79%, 93.88%, 93.88%, 94.08%, 94.12%\n",
      "step: 2500 \ttraining acc: 18.38%, 91.54%, 94.38%, 94.54%, 94.67%, 94.71%\n",
      "Test acc: [0.1991 0.875  0.8984 0.9    0.9004 0.9014 0.9014 0.9023 0.9023 0.903\n",
      " 0.9033]\n",
      "step: 2550 \ttraining acc: 19.42%, 93.08%, 94.38%, 94.50%, 94.50%, 94.54%\n",
      "step: 2600 \ttraining acc: 18.96%, 95.08%, 96.33%, 96.46%, 96.58%, 96.58%\n",
      "step: 2650 \ttraining acc: 23.96%, 94.38%, 96.08%, 96.21%, 96.33%, 96.42%\n",
      "step: 2700 \ttraining acc: 16.71%, 93.50%, 95.25%, 95.25%, 95.29%, 95.33%\n",
      "step: 2750 \ttraining acc: 22.46%, 92.33%, 95.62%, 95.71%, 95.71%, 95.83%\n",
      "step: 2800 \ttraining acc: 17.00%, 91.83%, 94.83%, 94.83%, 94.92%, 94.96%\n",
      "step: 2850 \ttraining acc: 19.46%, 93.00%, 94.67%, 94.92%, 94.96%, 95.08%\n",
      "step: 2900 \ttraining acc: 18.38%, 94.88%, 96.79%, 96.92%, 96.96%, 97.00%\n",
      "step: 2950 \ttraining acc: 19.75%, 93.50%, 95.75%, 95.88%, 95.92%, 95.96%\n",
      "step: 3000 \ttraining acc: 20.96%, 94.00%, 95.67%, 95.79%, 95.88%, 96.00%\n",
      "Test acc: [0.1995 0.8784 0.8994 0.9004 0.9014 0.9014 0.9023 0.9023 0.903  0.9033\n",
      " 0.9033]\n",
      "step: 3050 \ttraining acc: 20.08%, 94.38%, 96.75%, 96.79%, 96.83%, 96.96%\n",
      "step: 3100 \ttraining acc: 17.62%, 94.33%, 96.25%, 96.33%, 96.38%, 96.58%\n",
      "step: 3150 \ttraining acc: 21.96%, 93.12%, 95.21%, 95.29%, 95.38%, 95.38%\n",
      "step: 3200 \ttraining acc: 23.88%, 93.33%, 95.88%, 95.96%, 96.04%, 96.17%\n",
      "step: 3250 \ttraining acc: 20.58%, 92.08%, 93.50%, 93.58%, 93.67%, 93.75%\n",
      "step: 3300 \ttraining acc: 16.25%, 92.79%, 93.50%, 93.71%, 93.67%, 93.67%\n",
      "step: 3350 \ttraining acc: 21.71%, 93.08%, 95.12%, 95.25%, 95.42%, 95.42%\n",
      "step: 3400 \ttraining acc: 19.54%, 92.92%, 95.33%, 95.33%, 95.33%, 95.38%\n",
      "step: 3450 \ttraining acc: 18.92%, 92.96%, 95.67%, 95.71%, 95.75%, 95.83%\n",
      "step: 3500 \ttraining acc: 19.46%, 94.25%, 95.58%, 95.54%, 95.58%, 95.67%\n",
      "Test acc: [0.1958 0.879  0.8994 0.901  0.9014 0.902  0.9023 0.903  0.9033 0.904\n",
      " 0.904 ]\n",
      "step: 3550 \ttraining acc: 21.83%, 92.75%, 95.33%, 95.42%, 95.38%, 95.38%\n",
      "step: 3600 \ttraining acc: 18.50%, 93.08%, 95.21%, 95.29%, 95.29%, 95.46%\n",
      "step: 3650 \ttraining acc: 19.50%, 95.50%, 95.79%, 95.79%, 95.88%, 95.92%\n",
      "step: 3700 \ttraining acc: 21.04%, 93.04%, 94.75%, 94.71%, 94.75%, 94.79%\n",
      "step: 3750 \ttraining acc: 24.29%, 93.12%, 95.54%, 95.33%, 95.75%, 95.88%\n",
      "step: 3800 \ttraining acc: 20.17%, 94.79%, 96.08%, 96.42%, 96.42%, 96.42%\n",
      "step: 3850 \ttraining acc: 24.42%, 93.38%, 94.79%, 95.08%, 95.25%, 95.29%\n",
      "step: 3900 \ttraining acc: 25.42%, 94.04%, 95.83%, 96.25%, 96.25%, 96.29%\n",
      "step: 3950 \ttraining acc: 18.54%, 94.50%, 95.29%, 95.46%, 95.50%, 95.50%\n",
      "step: 4000 \ttraining acc: 20.33%, 93.71%, 94.46%, 94.79%, 94.83%, 94.83%\n",
      "Test acc: [0.2072 0.8833 0.9    0.901  0.902  0.9023 0.903  0.9033 0.9033 0.904\n",
      " 0.904 ]\n",
      "step: 4050 \ttraining acc: 19.92%, 93.17%, 95.42%, 95.38%, 95.38%, 95.38%\n",
      "step: 4100 \ttraining acc: 19.08%, 93.67%, 96.12%, 96.17%, 96.25%, 96.29%\n",
      "step: 4150 \ttraining acc: 17.88%, 93.62%, 95.04%, 95.12%, 95.12%, 95.12%\n",
      "step: 4200 \ttraining acc: 19.67%, 94.25%, 95.54%, 95.50%, 95.50%, 95.50%\n",
      "step: 4250 \ttraining acc: 18.42%, 94.17%, 95.96%, 96.04%, 96.04%, 96.12%\n",
      "step: 4300 \ttraining acc: 18.88%, 94.17%, 95.42%, 95.50%, 95.54%, 95.54%\n",
      "step: 4350 \ttraining acc: 21.46%, 94.00%, 95.25%, 95.29%, 95.29%, 95.38%\n",
      "step: 4400 \ttraining acc: 17.79%, 94.67%, 97.04%, 97.12%, 97.17%, 97.29%\n",
      "step: 4450 \ttraining acc: 18.83%, 96.46%, 96.88%, 96.96%, 97.08%, 97.12%\n",
      "step: 4500 \ttraining acc: 22.25%, 94.92%, 96.08%, 96.21%, 96.25%, 96.29%\n",
      "Test acc: [0.2019 0.89   0.9062 0.907  0.9077 0.908  0.9087 0.909  0.909  0.9097\n",
      " 0.91  ]\n",
      "step: 4550 \ttraining acc: 22.21%, 94.21%, 96.08%, 96.04%, 96.12%, 96.17%\n",
      "step: 4600 \ttraining acc: 24.00%, 94.25%, 95.96%, 96.08%, 96.04%, 96.12%\n",
      "step: 4650 \ttraining acc: 17.83%, 93.50%, 94.79%, 94.92%, 95.12%, 95.12%\n",
      "step: 4700 \ttraining acc: 22.00%, 94.00%, 95.62%, 96.04%, 96.12%, 96.17%\n",
      "step: 4750 \ttraining acc: 20.83%, 95.17%, 96.42%, 96.42%, 96.42%, 96.46%\n",
      "step: 4800 \ttraining acc: 16.54%, 95.92%, 97.50%, 97.50%, 97.54%, 97.54%\n",
      "step: 4850 \ttraining acc: 16.54%, 94.00%, 95.58%, 95.58%, 95.62%, 95.62%\n",
      "step: 4900 \ttraining acc: 21.12%, 94.67%, 95.83%, 95.96%, 96.04%, 96.08%\n",
      "step: 4950 \ttraining acc: 16.67%, 95.42%, 96.83%, 96.88%, 97.00%, 97.08%\n",
      "step: 5000 \ttraining acc: 21.21%, 93.83%, 95.08%, 95.08%, 95.17%, 95.17%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: [0.1968 0.895  0.907  0.908  0.9087 0.909  0.9097 0.91   0.91   0.9106\n",
      " 0.9106]\n",
      "step: 5050 \ttraining acc: 21.79%, 94.50%, 95.29%, 95.50%, 95.67%, 95.88%\n",
      "step: 5100 \ttraining acc: 20.75%, 92.25%, 94.21%, 94.42%, 94.50%, 94.58%\n",
      "step: 5150 \ttraining acc: 22.96%, 95.71%, 97.46%, 97.50%, 97.50%, 97.50%\n",
      "step: 5200 \ttraining acc: 18.25%, 94.12%, 94.54%, 94.58%, 94.67%, 94.62%\n",
      "step: 5250 \ttraining acc: 19.17%, 96.12%, 97.50%, 97.33%, 97.38%, 97.42%\n",
      "step: 5300 \ttraining acc: 16.29%, 95.12%, 96.17%, 96.17%, 96.17%, 96.21%\n",
      "step: 5350 \ttraining acc: 19.12%, 95.29%, 96.12%, 96.21%, 96.21%, 96.17%\n",
      "step: 5400 \ttraining acc: 17.96%, 96.08%, 97.04%, 97.12%, 97.17%, 97.25%\n",
      "step: 5450 \ttraining acc: 20.42%, 94.88%, 96.67%, 96.79%, 96.83%, 96.88%\n",
      "step: 5500 \ttraining acc: 21.79%, 95.88%, 96.92%, 97.08%, 97.08%, 97.08%\n",
      "Test acc: [0.2047 0.892  0.903  0.9043 0.905  0.9053 0.906  0.906  0.9062 0.9067\n",
      " 0.9067]\n",
      "step: 5550 \ttraining acc: 20.25%, 96.92%, 97.58%, 97.58%, 97.62%, 97.62%\n",
      "step: 5600 \ttraining acc: 20.62%, 96.21%, 97.71%, 97.79%, 97.79%, 97.88%\n",
      "step: 5650 \ttraining acc: 19.29%, 94.71%, 95.21%, 95.33%, 95.38%, 95.38%\n",
      "step: 5700 \ttraining acc: 22.50%, 95.17%, 96.00%, 96.00%, 96.08%, 96.08%\n",
      "step: 5750 \ttraining acc: 20.67%, 96.25%, 96.67%, 96.71%, 96.79%, 96.88%\n",
      "step: 5800 \ttraining acc: 18.25%, 95.38%, 96.54%, 96.54%, 96.62%, 96.62%\n",
      "step: 5850 \ttraining acc: 22.46%, 95.17%, 96.67%, 96.67%, 96.79%, 96.79%\n",
      "step: 5900 \ttraining acc: 23.21%, 95.25%, 97.00%, 97.00%, 97.08%, 97.17%\n",
      "step: 5950 \ttraining acc: 16.04%, 93.42%, 94.83%, 94.79%, 94.88%, 94.96%\n",
      "step: 6000 \ttraining acc: 24.12%, 96.04%, 97.17%, 97.21%, 97.25%, 97.25%\n",
      "Test acc: [0.1971 0.8994 0.911  0.912  0.9126 0.913  0.9136 0.914  0.914  0.9146\n",
      " 0.9146]\n",
      "step: 6050 \ttraining acc: 16.83%, 97.00%, 97.50%, 97.54%, 97.62%, 97.67%\n",
      "step: 6100 \ttraining acc: 17.83%, 96.25%, 97.29%, 97.33%, 97.38%, 97.38%\n",
      "step: 6150 \ttraining acc: 19.58%, 95.92%, 97.00%, 97.04%, 97.12%, 97.12%\n",
      "step: 6200 \ttraining acc: 18.08%, 96.25%, 96.79%, 96.92%, 96.92%, 96.96%\n",
      "step: 6250 \ttraining acc: 24.21%, 95.88%, 96.25%, 96.29%, 96.38%, 96.38%\n",
      "step: 6300 \ttraining acc: 19.21%, 97.38%, 97.46%, 97.62%, 97.62%, 97.67%\n",
      "step: 6350 \ttraining acc: 19.38%, 96.21%, 96.25%, 96.88%, 96.83%, 96.88%\n",
      "step: 6400 \ttraining acc: 15.83%, 94.00%, 97.12%, 97.21%, 97.29%, 97.38%\n",
      "step: 6450 \ttraining acc: 21.92%, 95.25%, 95.79%, 95.88%, 95.92%, 96.00%\n",
      "step: 6500 \ttraining acc: 18.46%, 95.42%, 96.46%, 96.54%, 96.54%, 96.58%\n",
      "Test acc: [0.1979 0.9053 0.914  0.9146 0.9155 0.9155 0.916  0.916  0.9165 0.9165\n",
      " 0.917 ]\n",
      "step: 6550 \ttraining acc: 17.42%, 96.04%, 96.62%, 96.75%, 96.79%, 96.88%\n",
      "step: 6600 \ttraining acc: 19.92%, 95.71%, 97.17%, 97.29%, 97.46%, 97.46%\n",
      "step: 6650 \ttraining acc: 17.00%, 95.71%, 96.79%, 96.88%, 96.88%, 96.92%\n",
      "step: 6700 \ttraining acc: 17.12%, 95.33%, 96.25%, 96.50%, 96.50%, 96.54%\n",
      "step: 6750 \ttraining acc: 22.25%, 96.92%, 97.29%, 97.29%, 97.33%, 97.33%\n",
      "step: 6800 \ttraining acc: 20.46%, 94.46%, 95.88%, 96.04%, 96.12%, 96.12%\n",
      "step: 6850 \ttraining acc: 20.17%, 97.42%, 97.92%, 97.96%, 98.00%, 98.00%\n",
      "step: 6900 \ttraining acc: 20.08%, 95.62%, 96.21%, 96.17%, 96.17%, 96.21%\n",
      "step: 6950 \ttraining acc: 16.83%, 96.04%, 96.71%, 96.75%, 96.79%, 96.79%\n",
      "step: 7000 \ttraining acc: 17.54%, 96.71%, 97.38%, 97.46%, 97.46%, 97.46%\n",
      "Test acc: [0.2015 0.901  0.909  0.91   0.9106 0.911  0.911  0.9116 0.9116 0.9116\n",
      " 0.912 ]\n",
      "step: 7050 \ttraining acc: 19.00%, 97.25%, 97.54%, 97.54%, 97.58%, 97.62%\n",
      "step: 7100 \ttraining acc: 21.17%, 95.67%, 96.71%, 96.79%, 96.79%, 96.75%\n",
      "step: 7150 \ttraining acc: 22.33%, 97.62%, 98.00%, 98.08%, 98.08%, 98.08%\n",
      "step: 7200 \ttraining acc: 19.29%, 97.25%, 97.50%, 97.54%, 97.54%, 97.58%\n",
      "step: 7250 \ttraining acc: 20.12%, 97.62%, 98.25%, 98.38%, 98.42%, 98.42%\n",
      "step: 7300 \ttraining acc: 19.12%, 96.71%, 97.29%, 97.42%, 97.42%, 97.42%\n",
      "step: 7350 \ttraining acc: 21.00%, 97.00%, 97.21%, 97.42%, 97.58%, 97.67%\n",
      "step: 7400 \ttraining acc: 15.38%, 96.67%, 97.38%, 97.38%, 97.33%, 97.33%\n",
      "step: 7450 \ttraining acc: 19.46%, 97.08%, 98.08%, 98.08%, 98.08%, 98.08%\n",
      "step: 7500 \ttraining acc: 21.71%, 93.38%, 94.42%, 94.62%, 94.71%, 94.71%\n",
      "Test acc: [0.1997 0.909  0.9165 0.917  0.9175 0.918  0.9185 0.9185 0.919  0.919\n",
      " 0.9194]\n",
      "step: 7550 \ttraining acc: 15.92%, 97.58%, 98.12%, 98.12%, 98.12%, 98.21%\n",
      "step: 7600 \ttraining acc: 17.54%, 96.88%, 97.67%, 97.96%, 97.96%, 97.96%\n",
      "step: 7650 \ttraining acc: 22.42%, 96.96%, 97.42%, 97.42%, 97.42%, 97.42%\n",
      "step: 7700 \ttraining acc: 19.83%, 96.96%, 97.21%, 97.25%, 97.25%, 97.29%\n",
      "step: 7750 \ttraining acc: 18.88%, 95.83%, 96.33%, 96.54%, 96.54%, 96.54%\n",
      "step: 7800 \ttraining acc: 21.71%, 96.42%, 96.50%, 96.50%, 96.62%, 96.62%\n",
      "step: 7850 \ttraining acc: 21.75%, 96.54%, 97.50%, 97.50%, 97.46%, 97.50%\n",
      "step: 7900 \ttraining acc: 18.04%, 94.88%, 95.46%, 95.54%, 95.58%, 95.58%\n",
      "step: 7950 \ttraining acc: 20.38%, 96.08%, 97.00%, 97.00%, 97.00%, 97.04%\n",
      "step: 8000 \ttraining acc: 22.79%, 97.04%, 97.29%, 97.42%, 97.42%, 97.42%\n",
      "Test acc: [0.2021 0.909  0.9165 0.917  0.9175 0.918  0.918  0.9185 0.9185 0.919\n",
      " 0.919 ]\n",
      "step: 8050 \ttraining acc: 17.29%, 97.04%, 97.46%, 97.46%, 97.50%, 97.50%\n",
      "step: 8100 \ttraining acc: 15.83%, 96.17%, 96.92%, 96.96%, 96.96%, 96.96%\n",
      "step: 8150 \ttraining acc: 18.62%, 95.79%, 96.67%, 96.75%, 96.83%, 96.88%\n",
      "step: 8200 \ttraining acc: 18.83%, 97.33%, 98.00%, 98.04%, 98.08%, 98.12%\n",
      "step: 8250 \ttraining acc: 17.58%, 95.71%, 96.75%, 96.92%, 96.92%, 96.96%\n",
      "step: 8300 \ttraining acc: 23.00%, 95.62%, 96.46%, 96.46%, 96.50%, 96.54%\n",
      "step: 8350 \ttraining acc: 21.08%, 96.21%, 97.12%, 97.25%, 97.25%, 97.25%\n",
      "step: 8400 \ttraining acc: 21.25%, 94.92%, 96.12%, 96.21%, 96.21%, 96.33%\n",
      "step: 8450 \ttraining acc: 17.50%, 97.04%, 97.54%, 97.54%, 97.54%, 97.54%\n",
      "step: 8500 \ttraining acc: 21.00%, 97.00%, 97.96%, 97.96%, 97.96%, 97.96%\n",
      "Test acc: [0.2017 0.909  0.917  0.9175 0.918  0.9185 0.9185 0.919  0.919  0.9194\n",
      " 0.9194]\n",
      "step: 8550 \ttraining acc: 21.62%, 96.08%, 96.92%, 96.96%, 97.00%, 97.04%\n",
      "step: 8600 \ttraining acc: 24.12%, 96.67%, 97.62%, 97.62%, 97.62%, 97.67%\n",
      "step: 8650 \ttraining acc: 18.62%, 97.04%, 97.62%, 97.67%, 97.67%, 97.75%\n",
      "step: 8700 \ttraining acc: 20.17%, 97.29%, 98.17%, 98.21%, 98.21%, 98.17%\n",
      "step: 8750 \ttraining acc: 21.71%, 96.12%, 97.00%, 97.12%, 97.08%, 97.21%\n",
      "step: 8800 \ttraining acc: 25.42%, 96.21%, 96.67%, 96.71%, 96.79%, 96.88%\n",
      "step: 8850 \ttraining acc: 20.75%, 96.71%, 96.92%, 96.96%, 97.00%, 96.96%\n",
      "step: 8900 \ttraining acc: 21.17%, 97.83%, 98.46%, 98.62%, 98.62%, 98.62%\n",
      "step: 8950 \ttraining acc: 17.58%, 97.08%, 97.75%, 97.71%, 97.75%, 97.75%\n",
      "step: 9000 \ttraining acc: 22.71%, 95.58%, 96.50%, 96.67%, 96.71%, 96.71%\n",
      "Test acc: [0.1975 0.905  0.9116 0.912  0.913  0.913  0.9136 0.9136 0.914  0.914\n",
      " 0.9146]\n",
      "step: 9050 \ttraining acc: 18.04%, 97.17%, 97.54%, 97.58%, 97.62%, 97.67%\n",
      "step: 9100 \ttraining acc: 19.04%, 97.75%, 97.67%, 97.71%, 97.71%, 97.75%\n",
      "step: 9150 \ttraining acc: 17.62%, 95.62%, 95.71%, 95.79%, 95.83%, 95.88%\n",
      "step: 9200 \ttraining acc: 15.62%, 96.79%, 97.42%, 97.46%, 97.46%, 97.50%\n",
      "step: 9250 \ttraining acc: 19.29%, 97.38%, 97.54%, 97.62%, 97.62%, 97.67%\n",
      "step: 9300 \ttraining acc: 20.71%, 94.83%, 95.54%, 95.54%, 95.58%, 95.67%\n",
      "step: 9350 \ttraining acc: 18.21%, 96.75%, 97.92%, 98.00%, 98.00%, 98.00%\n",
      "step: 9400 \ttraining acc: 17.46%, 97.29%, 97.54%, 97.54%, 97.54%, 97.58%\n",
      "step: 9450 \ttraining acc: 22.50%, 96.54%, 96.92%, 96.96%, 96.96%, 96.96%\n",
      "step: 9500 \ttraining acc: 19.46%, 96.29%, 96.88%, 96.88%, 96.88%, 96.88%\n",
      "Test acc: [0.2014 0.913  0.919  0.9194 0.92   0.9204 0.9204 0.921  0.921  0.9214\n",
      " 0.9214]\n",
      "step: 9550 \ttraining acc: 16.08%, 97.79%, 98.12%, 98.21%, 98.25%, 98.29%\n",
      "step: 9600 \ttraining acc: 19.00%, 96.42%, 97.08%, 97.08%, 97.08%, 97.08%\n",
      "step: 9650 \ttraining acc: 21.33%, 97.33%, 97.71%, 97.79%, 97.88%, 97.92%\n",
      "step: 9700 \ttraining acc: 21.58%, 97.38%, 98.00%, 98.08%, 98.08%, 98.08%\n",
      "step: 9750 \ttraining acc: 21.54%, 97.25%, 97.67%, 97.71%, 97.75%, 97.83%\n",
      "step: 9800 \ttraining acc: 21.54%, 95.67%, 96.54%, 96.58%, 96.62%, 96.62%\n",
      "step: 9850 \ttraining acc: 20.75%, 96.54%, 97.29%, 97.29%, 97.29%, 97.29%\n",
      "step: 9900 \ttraining acc: 26.67%, 96.83%, 97.29%, 97.29%, 97.29%, 97.33%\n",
      "step: 9950 \ttraining acc: 20.12%, 97.00%, 97.33%, 97.33%, 97.29%, 97.33%\n",
      "step: 10000 \ttraining acc: 21.00%, 96.00%, 96.29%, 96.42%, 96.46%, 96.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: [0.1986 0.908  0.9155 0.916  0.9165 0.917  0.917  0.9175 0.9175 0.918\n",
      " 0.918 ]\n",
      "step: 10050 \ttraining acc: 20.83%, 95.17%, 95.96%, 96.17%, 96.12%, 96.12%\n",
      "step: 10100 \ttraining acc: 19.38%, 96.67%, 97.17%, 97.21%, 97.25%, 97.29%\n",
      "step: 10150 \ttraining acc: 25.04%, 97.58%, 98.33%, 98.50%, 98.50%, 98.54%\n",
      "step: 10200 \ttraining acc: 17.04%, 96.92%, 97.29%, 97.42%, 97.42%, 97.42%\n",
      "step: 10250 \ttraining acc: 23.62%, 96.21%, 96.75%, 97.29%, 97.29%, 97.33%\n",
      "step: 10300 \ttraining acc: 19.00%, 97.00%, 97.08%, 97.12%, 97.12%, 97.12%\n",
      "step: 10350 \ttraining acc: 21.54%, 96.46%, 97.42%, 97.46%, 97.46%, 97.50%\n",
      "step: 10400 \ttraining acc: 19.67%, 96.75%, 97.42%, 97.54%, 97.62%, 97.62%\n",
      "step: 10450 \ttraining acc: 18.71%, 96.71%, 97.08%, 97.12%, 97.04%, 97.08%\n",
      "step: 10500 \ttraining acc: 19.75%, 97.25%, 97.54%, 97.58%, 97.67%, 97.71%\n",
      "Test acc: [0.2028 0.911  0.918  0.9185 0.9185 0.919  0.919  0.9194 0.9194 0.92\n",
      " 0.92  ]\n",
      "step: 10550 \ttraining acc: 21.58%, 96.46%, 97.21%, 97.21%, 97.33%, 97.38%\n",
      "step: 10600 \ttraining acc: 22.12%, 96.58%, 96.71%, 96.75%, 96.83%, 96.88%\n",
      "step: 10650 \ttraining acc: 25.62%, 97.00%, 97.46%, 97.46%, 97.50%, 97.54%\n",
      "step: 10700 \ttraining acc: 17.75%, 97.12%, 97.33%, 97.33%, 97.33%, 97.38%\n",
      "step: 10750 \ttraining acc: 24.83%, 95.50%, 96.12%, 96.12%, 96.12%, 96.12%\n",
      "step: 10800 \ttraining acc: 17.29%, 95.83%, 96.50%, 96.50%, 96.50%, 96.50%\n",
      "step: 10850 \ttraining acc: 20.79%, 96.62%, 97.83%, 97.92%, 97.96%, 97.96%\n",
      "step: 10900 \ttraining acc: 18.88%, 96.71%, 96.96%, 96.96%, 97.00%, 97.04%\n",
      "step: 10950 \ttraining acc: 20.75%, 97.29%, 97.50%, 97.50%, 97.54%, 97.54%\n",
      "step: 11000 \ttraining acc: 22.29%, 96.71%, 97.33%, 97.33%, 97.33%, 97.29%\n",
      "Test acc: [0.1973 0.909  0.9155 0.916  0.9165 0.917  0.917  0.9175 0.9175 0.9175\n",
      " 0.918 ]\n",
      "step: 11050 \ttraining acc: 19.83%, 97.17%, 97.83%, 97.88%, 97.88%, 97.92%\n",
      "step: 11100 \ttraining acc: 15.58%, 96.92%, 97.67%, 97.67%, 97.62%, 97.62%\n",
      "step: 11150 \ttraining acc: 20.08%, 98.21%, 98.33%, 98.38%, 98.42%, 98.42%\n",
      "step: 11200 \ttraining acc: 21.46%, 96.04%, 96.83%, 96.88%, 96.88%, 96.88%\n",
      "step: 11250 \ttraining acc: 19.38%, 96.29%, 96.75%, 96.79%, 96.79%, 96.79%\n",
      "step: 11300 \ttraining acc: 21.50%, 96.62%, 97.04%, 97.04%, 97.12%, 97.12%\n",
      "step: 11350 \ttraining acc: 21.21%, 98.08%, 98.62%, 98.67%, 98.67%, 98.71%\n",
      "step: 11400 \ttraining acc: 18.54%, 97.79%, 98.08%, 98.08%, 98.08%, 98.08%\n",
      "step: 11450 \ttraining acc: 17.71%, 96.92%, 97.50%, 97.54%, 97.62%, 97.67%\n",
      "step: 11500 \ttraining acc: 21.50%, 96.38%, 97.46%, 97.46%, 97.50%, 97.54%\n",
      "Test acc: [0.2043 0.9097 0.917  0.9175 0.918  0.9185 0.9185 0.919  0.919  0.9194\n",
      " 0.9194]\n",
      "step: 11550 \ttraining acc: 19.92%, 95.75%, 97.92%, 97.96%, 98.00%, 98.00%\n",
      "step: 11600 \ttraining acc: 22.88%, 96.75%, 97.67%, 97.75%, 97.75%, 97.79%\n",
      "step: 11650 \ttraining acc: 19.21%, 96.42%, 97.38%, 97.42%, 97.50%, 97.50%\n",
      "step: 11700 \ttraining acc: 21.54%, 95.17%, 96.29%, 96.29%, 96.29%, 96.33%\n",
      "step: 11750 \ttraining acc: 17.79%, 96.92%, 97.50%, 97.62%, 97.67%, 97.67%\n",
      "step: 11800 \ttraining acc: 18.83%, 97.25%, 97.42%, 97.46%, 97.54%, 97.62%\n",
      "step: 11850 \ttraining acc: 18.83%, 96.71%, 97.04%, 97.08%, 97.08%, 97.21%\n",
      "step: 11900 \ttraining acc: 20.58%, 95.50%, 96.67%, 96.75%, 96.75%, 96.79%\n",
      "step: 11950 \ttraining acc: 22.58%, 95.83%, 97.38%, 97.42%, 97.42%, 97.42%\n",
      "step: 12000 \ttraining acc: 19.71%, 96.62%, 97.25%, 97.42%, 97.42%, 97.42%\n",
      "Test acc: [0.2032 0.912  0.918  0.9185 0.919  0.919  0.9194 0.92   0.92   0.92\n",
      " 0.9204]\n",
      "step: 12050 \ttraining acc: 18.17%, 98.42%, 98.50%, 98.50%, 98.54%, 98.54%\n",
      "step: 12100 \ttraining acc: 23.38%, 97.75%, 98.29%, 98.33%, 98.33%, 98.33%\n",
      "step: 12150 \ttraining acc: 21.54%, 96.25%, 96.75%, 96.79%, 96.79%, 96.79%\n",
      "step: 12200 \ttraining acc: 16.04%, 96.25%, 96.58%, 96.62%, 96.62%, 96.62%\n",
      "step: 12250 \ttraining acc: 20.42%, 97.29%, 98.00%, 98.00%, 98.00%, 98.00%\n",
      "step: 12300 \ttraining acc: 24.17%, 97.00%, 97.46%, 97.50%, 97.50%, 97.50%\n",
      "step: 12350 \ttraining acc: 17.12%, 97.21%, 98.62%, 98.67%, 98.71%, 98.71%\n",
      "step: 12400 \ttraining acc: 21.88%, 97.33%, 97.50%, 97.50%, 97.50%, 97.50%\n",
      "step: 12450 \ttraining acc: 24.08%, 96.79%, 96.92%, 96.92%, 96.96%, 96.96%\n",
      "step: 12500 \ttraining acc: 14.62%, 98.17%, 98.33%, 98.42%, 98.42%, 98.42%\n",
      "Test acc: [0.201  0.913  0.9194 0.9194 0.92   0.9204 0.921  0.921  0.9214 0.9214\n",
      " 0.9214]\n",
      "step: 12550 \ttraining acc: 16.04%, 95.79%, 96.04%, 96.04%, 96.00%, 96.00%\n",
      "step: 12600 \ttraining acc: 21.12%, 96.42%, 97.42%, 97.50%, 97.50%, 97.58%\n",
      "step: 12650 \ttraining acc: 16.96%, 96.92%, 97.62%, 97.62%, 97.62%, 97.62%\n",
      "step: 12700 \ttraining acc: 18.21%, 96.58%, 97.25%, 97.25%, 97.29%, 97.29%\n",
      "step: 12750 \ttraining acc: 27.96%, 97.71%, 97.83%, 97.92%, 97.92%, 97.96%\n",
      "step: 12800 \ttraining acc: 19.50%, 96.42%, 97.42%, 97.50%, 97.58%, 97.58%\n",
      "step: 12850 \ttraining acc: 20.67%, 95.54%, 97.00%, 97.00%, 97.04%, 97.04%\n",
      "step: 12900 \ttraining acc: 20.62%, 97.21%, 97.96%, 98.00%, 98.00%, 98.00%\n",
      "step: 12950 \ttraining acc: 18.25%, 97.08%, 97.96%, 98.00%, 98.00%, 98.04%\n",
      "step: 13000 \ttraining acc: 19.75%, 96.46%, 97.79%, 97.79%, 97.79%, 97.83%\n",
      "Test acc: [0.203  0.915  0.921  0.9214 0.922  0.9224 0.9224 0.9224 0.923  0.923\n",
      " 0.923 ]\n",
      "step: 13050 \ttraining acc: 19.08%, 97.29%, 98.04%, 98.17%, 98.21%, 98.29%\n",
      "step: 13100 \ttraining acc: 21.08%, 97.25%, 97.75%, 97.75%, 97.75%, 97.75%\n",
      "step: 13150 \ttraining acc: 21.08%, 96.00%, 97.04%, 97.04%, 97.04%, 97.04%\n",
      "step: 13200 \ttraining acc: 17.00%, 97.12%, 97.50%, 97.54%, 97.54%, 97.58%\n",
      "step: 13250 \ttraining acc: 18.62%, 97.54%, 97.54%, 97.54%, 97.58%, 97.62%\n",
      "step: 13300 \ttraining acc: 22.42%, 97.08%, 97.54%, 97.50%, 97.50%, 97.54%\n",
      "step: 13350 \ttraining acc: 21.21%, 97.21%, 97.92%, 98.00%, 98.04%, 98.08%\n",
      "step: 13400 \ttraining acc: 20.33%, 97.29%, 97.29%, 97.29%, 97.29%, 97.33%\n",
      "step: 13450 \ttraining acc: 19.75%, 98.04%, 98.17%, 98.21%, 98.21%, 98.21%\n",
      "step: 13500 \ttraining acc: 19.96%, 97.67%, 98.17%, 98.29%, 98.29%, 98.29%\n",
      "Test acc: [0.2019 0.9087 0.9146 0.9155 0.916  0.9165 0.9165 0.917  0.917  0.917\n",
      " 0.9175]\n",
      "step: 13550 \ttraining acc: 19.29%, 98.50%, 98.54%, 98.50%, 98.54%, 98.54%\n",
      "step: 13600 \ttraining acc: 16.79%, 95.96%, 96.71%, 96.79%, 96.92%, 96.92%\n",
      "step: 13650 \ttraining acc: 20.42%, 98.58%, 98.71%, 98.71%, 98.75%, 98.71%\n",
      "step: 13700 \ttraining acc: 21.54%, 96.17%, 96.46%, 96.46%, 96.46%, 96.50%\n",
      "step: 13750 \ttraining acc: 20.75%, 98.00%, 98.25%, 98.25%, 98.25%, 98.25%\n",
      "step: 13800 \ttraining acc: 22.25%, 95.92%, 96.46%, 96.46%, 96.46%, 96.58%\n",
      "step: 13850 \ttraining acc: 18.96%, 97.04%, 97.79%, 97.79%, 97.79%, 97.75%\n",
      "step: 13900 \ttraining acc: 19.42%, 96.25%, 97.58%, 97.58%, 97.58%, 97.58%\n",
      "step: 13950 \ttraining acc: 20.29%, 97.21%, 97.71%, 97.71%, 97.75%, 97.79%\n",
      "step: 14000 \ttraining acc: 19.83%, 96.96%, 97.54%, 97.67%, 97.67%, 97.62%\n",
      "Test acc: [0.2013 0.9087 0.9165 0.917  0.9175 0.9175 0.918  0.918  0.9185 0.9185\n",
      " 0.9185]\n",
      "step: 14050 \ttraining acc: 15.17%, 96.71%, 97.17%, 97.21%, 97.21%, 97.21%\n",
      "step: 14100 \ttraining acc: 19.38%, 96.92%, 97.75%, 97.79%, 97.79%, 97.79%\n",
      "step: 14150 \ttraining acc: 20.25%, 97.88%, 98.75%, 98.75%, 98.75%, 98.75%\n",
      "step: 14200 \ttraining acc: 23.00%, 97.46%, 97.88%, 97.88%, 97.88%, 97.88%\n",
      "step: 14250 \ttraining acc: 21.33%, 96.38%, 97.42%, 97.46%, 97.46%, 97.50%\n",
      "step: 14300 \ttraining acc: 18.38%, 96.12%, 96.83%, 96.92%, 96.92%, 97.00%\n",
      "step: 14350 \ttraining acc: 22.83%, 96.33%, 96.96%, 97.04%, 97.12%, 97.17%\n",
      "step: 14400 \ttraining acc: 22.00%, 96.58%, 97.67%, 97.71%, 97.71%, 97.71%\n",
      "step: 14450 \ttraining acc: 21.54%, 96.33%, 97.62%, 97.67%, 97.67%, 97.67%\n",
      "step: 14500 \ttraining acc: 23.96%, 97.00%, 97.62%, 97.67%, 97.67%, 97.71%\n",
      "Test acc: [0.1996 0.91   0.9165 0.917  0.9175 0.9175 0.9175 0.918  0.9185 0.9185\n",
      " 0.9185]\n",
      "step: 14550 \ttraining acc: 16.54%, 95.46%, 96.21%, 96.29%, 96.29%, 96.29%\n",
      "step: 14600 \ttraining acc: 19.71%, 97.17%, 98.00%, 98.00%, 98.00%, 98.00%\n",
      "step: 14650 \ttraining acc: 19.42%, 97.62%, 98.04%, 98.08%, 98.08%, 98.08%\n",
      "step: 14700 \ttraining acc: 20.08%, 97.21%, 97.83%, 97.88%, 97.88%, 97.92%\n",
      "step: 14750 \ttraining acc: 19.92%, 97.21%, 97.42%, 97.46%, 97.46%, 97.54%\n",
      "step: 14800 \ttraining acc: 20.54%, 97.29%, 98.54%, 98.58%, 98.58%, 98.58%\n",
      "step: 14850 \ttraining acc: 19.00%, 95.42%, 96.38%, 96.42%, 96.58%, 96.54%\n",
      "step: 14900 \ttraining acc: 18.21%, 97.38%, 97.92%, 97.92%, 98.00%, 97.96%\n",
      "step: 14950 \ttraining acc: 18.88%, 95.58%, 97.08%, 97.12%, 97.17%, 97.17%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 15000 \ttraining acc: 21.17%, 96.33%, 97.00%, 97.00%, 96.96%, 97.00%\n",
      "Test acc: [0.2002 0.9146 0.922  0.923  0.9233 0.9233 0.9233 0.924  0.924  0.924\n",
      " 0.9243]\n",
      "step: 15050 \ttraining acc: 18.58%, 96.46%, 96.75%, 96.75%, 96.75%, 96.75%\n",
      "step: 15100 \ttraining acc: 14.50%, 94.83%, 96.46%, 96.46%, 96.54%, 96.58%\n",
      "step: 15150 \ttraining acc: 20.88%, 97.83%, 98.83%, 98.88%, 98.88%, 98.92%\n",
      "step: 15200 \ttraining acc: 18.92%, 96.67%, 97.04%, 97.08%, 97.08%, 97.17%\n",
      "step: 15250 \ttraining acc: 18.79%, 96.33%, 97.96%, 98.04%, 98.04%, 98.12%\n",
      "step: 15300 \ttraining acc: 23.21%, 98.79%, 99.12%, 99.12%, 99.21%, 99.21%\n",
      "step: 15350 \ttraining acc: 19.71%, 97.33%, 98.25%, 98.25%, 98.25%, 98.29%\n",
      "step: 15400 \ttraining acc: 18.88%, 97.62%, 98.08%, 98.12%, 98.12%, 98.17%\n",
      "step: 15450 \ttraining acc: 18.33%, 96.12%, 97.08%, 97.17%, 97.21%, 97.21%\n",
      "step: 15500 \ttraining acc: 15.92%, 96.17%, 96.96%, 97.00%, 97.04%, 97.08%\n",
      "Test acc: [0.2009 0.9126 0.92   0.9204 0.921  0.921  0.9214 0.922  0.9224 0.9224\n",
      " 0.9224]\n",
      "step: 15550 \ttraining acc: 17.67%, 96.12%, 97.54%, 97.54%, 97.58%, 97.58%\n",
      "step: 15600 \ttraining acc: 19.96%, 96.96%, 97.58%, 97.67%, 97.67%, 97.62%\n",
      "step: 15650 \ttraining acc: 19.71%, 96.38%, 97.00%, 97.08%, 97.08%, 97.12%\n",
      "step: 15700 \ttraining acc: 17.83%, 97.25%, 98.54%, 98.58%, 98.58%, 98.58%\n",
      "step: 15750 \ttraining acc: 16.33%, 96.75%, 97.38%, 97.42%, 97.42%, 97.46%\n",
      "step: 15800 \ttraining acc: 15.54%, 97.38%, 97.75%, 97.92%, 97.92%, 97.92%\n",
      "step: 15850 \ttraining acc: 20.33%, 96.25%, 97.08%, 97.08%, 97.12%, 97.17%\n",
      "step: 15900 \ttraining acc: 18.83%, 97.21%, 98.50%, 98.50%, 98.50%, 98.58%\n",
      "step: 15950 \ttraining acc: 19.12%, 97.46%, 97.88%, 97.88%, 97.88%, 97.92%\n",
      "step: 16000 \ttraining acc: 17.00%, 97.04%, 98.08%, 98.12%, 98.17%, 98.17%\n",
      "Test acc: [0.196  0.912  0.9204 0.921  0.921  0.9214 0.9214 0.922  0.922  0.922\n",
      " 0.9224]\n",
      "step: 16050 \ttraining acc: 21.38%, 97.83%, 97.58%, 97.58%, 97.62%, 97.62%\n",
      "step: 16100 \ttraining acc: 19.71%, 98.33%, 98.79%, 98.83%, 98.83%, 98.83%\n",
      "step: 16150 \ttraining acc: 20.88%, 98.08%, 98.46%, 98.50%, 98.50%, 98.50%\n",
      "step: 16200 \ttraining acc: 17.96%, 94.96%, 95.62%, 95.92%, 95.50%, 95.83%\n",
      "step: 16250 \ttraining acc: 22.42%, 97.17%, 97.50%, 97.54%, 97.58%, 97.58%\n",
      "step: 16300 \ttraining acc: 23.04%, 97.04%, 97.67%, 97.79%, 97.83%, 97.88%\n",
      "step: 16350 \ttraining acc: 23.12%, 96.96%, 97.38%, 97.33%, 97.38%, 97.38%\n",
      "step: 16400 \ttraining acc: 20.58%, 97.58%, 98.12%, 98.21%, 98.25%, 98.29%\n",
      "step: 16450 \ttraining acc: 18.38%, 96.92%, 97.50%, 97.67%, 97.67%, 97.75%\n",
      "step: 16500 \ttraining acc: 14.54%, 97.04%, 97.83%, 97.83%, 97.83%, 97.83%\n",
      "Test acc: [0.2042 0.91   0.921  0.9214 0.922  0.9224 0.9224 0.9224 0.923  0.923\n",
      " 0.923 ]\n",
      "step: 16550 \ttraining acc: 17.08%, 96.96%, 97.38%, 97.42%, 97.42%, 97.42%\n",
      "step: 16600 \ttraining acc: 15.58%, 95.54%, 97.25%, 97.25%, 97.25%, 97.25%\n",
      "step: 16650 \ttraining acc: 17.62%, 96.00%, 97.04%, 97.04%, 97.00%, 96.96%\n",
      "step: 16700 \ttraining acc: 19.08%, 97.25%, 97.50%, 97.50%, 97.54%, 97.54%\n",
      "step: 16750 \ttraining acc: 18.71%, 98.00%, 98.38%, 98.42%, 98.42%, 98.42%\n",
      "step: 16800 \ttraining acc: 17.46%, 96.58%, 97.71%, 97.88%, 98.04%, 98.08%\n",
      "step: 16850 \ttraining acc: 22.58%, 96.75%, 98.17%, 98.21%, 98.25%, 98.25%\n",
      "step: 16900 \ttraining acc: 19.50%, 97.17%, 97.50%, 97.54%, 97.62%, 97.67%\n",
      "step: 16950 \ttraining acc: 21.29%, 98.38%, 99.12%, 99.12%, 99.12%, 99.17%\n",
      "step: 17000 \ttraining acc: 16.33%, 95.29%, 97.58%, 97.62%, 97.62%, 97.67%\n",
      "Test acc: [0.1985 0.9126 0.9214 0.922  0.9224 0.923  0.923  0.9233 0.9233 0.9233\n",
      " 0.9233]\n",
      "step: 17050 \ttraining acc: 18.92%, 96.71%, 97.42%, 97.42%, 97.42%, 97.42%\n",
      "step: 17100 \ttraining acc: 25.25%, 97.83%, 98.54%, 98.58%, 98.58%, 98.58%\n",
      "step: 17150 \ttraining acc: 19.75%, 95.62%, 96.79%, 96.67%, 96.67%, 96.67%\n",
      "step: 17200 \ttraining acc: 19.96%, 96.88%, 97.75%, 97.88%, 97.92%, 97.96%\n",
      "step: 17250 \ttraining acc: 22.54%, 97.54%, 98.38%, 98.38%, 98.38%, 98.46%\n",
      "step: 17300 \ttraining acc: 22.33%, 97.38%, 97.88%, 97.96%, 98.00%, 98.00%\n",
      "step: 17350 \ttraining acc: 19.92%, 96.46%, 97.92%, 97.96%, 98.12%, 98.12%\n",
      "step: 17400 \ttraining acc: 14.29%, 97.29%, 97.54%, 97.50%, 97.50%, 97.50%\n",
      "step: 17450 \ttraining acc: 19.25%, 96.38%, 97.83%, 97.83%, 97.83%, 97.92%\n",
      "step: 17500 \ttraining acc: 19.33%, 97.17%, 98.33%, 98.33%, 98.33%, 98.38%\n",
      "Test acc: [0.1971 0.9106 0.9204 0.921  0.9214 0.922  0.922  0.9224 0.9224 0.923\n",
      " 0.923 ]\n",
      "step: 17550 \ttraining acc: 16.71%, 96.25%, 97.38%, 97.42%, 97.42%, 97.38%\n",
      "step: 17600 \ttraining acc: 21.08%, 96.33%, 97.67%, 97.75%, 97.75%, 97.83%\n",
      "step: 17650 \ttraining acc: 18.54%, 96.71%, 97.58%, 97.67%, 97.71%, 97.71%\n",
      "step: 17700 \ttraining acc: 20.92%, 96.04%, 98.17%, 98.21%, 98.21%, 98.21%\n",
      "step: 17750 \ttraining acc: 17.67%, 98.04%, 98.50%, 98.58%, 98.58%, 98.58%\n",
      "step: 17800 \ttraining acc: 20.79%, 96.33%, 96.96%, 97.04%, 97.12%, 97.17%\n",
      "step: 17850 \ttraining acc: 17.25%, 96.71%, 97.50%, 97.50%, 97.54%, 97.58%\n",
      "step: 17900 \ttraining acc: 17.83%, 97.46%, 97.67%, 97.67%, 97.67%, 97.75%\n",
      "step: 17950 \ttraining acc: 20.79%, 97.42%, 97.92%, 97.92%, 97.92%, 97.92%\n",
      "step: 18000 \ttraining acc: 18.83%, 97.29%, 98.67%, 98.67%, 98.62%, 98.58%\n",
      "Test acc: [0.2021 0.9087 0.92   0.9204 0.9204 0.921  0.921  0.9214 0.9214 0.9214\n",
      " 0.922 ]\n",
      "step: 18050 \ttraining acc: 18.08%, 96.42%, 96.88%, 96.92%, 96.96%, 97.00%\n",
      "step: 18100 \ttraining acc: 22.79%, 96.54%, 98.00%, 98.00%, 98.00%, 98.00%\n",
      "step: 18150 \ttraining acc: 20.62%, 94.67%, 95.79%, 95.79%, 95.83%, 95.83%\n",
      "step: 18200 \ttraining acc: 24.12%, 95.58%, 97.04%, 97.08%, 97.17%, 97.17%\n",
      "step: 18250 \ttraining acc: 13.29%, 97.96%, 98.33%, 98.42%, 98.42%, 98.42%\n",
      "step: 18300 \ttraining acc: 22.38%, 97.62%, 98.17%, 98.21%, 98.25%, 98.25%\n",
      "step: 18350 \ttraining acc: 20.62%, 95.96%, 97.46%, 97.50%, 97.58%, 97.54%\n",
      "step: 18400 \ttraining acc: 25.58%, 97.46%, 98.29%, 98.29%, 98.29%, 98.29%\n",
      "step: 18450 \ttraining acc: 16.04%, 97.17%, 97.79%, 97.79%, 97.83%, 97.83%\n",
      "step: 18500 \ttraining acc: 17.38%, 97.62%, 97.58%, 97.96%, 97.92%, 97.96%\n",
      "Test acc: [0.201  0.9053 0.917  0.918  0.918  0.9185 0.9185 0.919  0.919  0.919\n",
      " 0.9194]\n",
      "step: 18550 \ttraining acc: 23.54%, 95.42%, 97.42%, 97.50%, 97.50%, 97.50%\n",
      "step: 18600 \ttraining acc: 16.00%, 97.79%, 98.00%, 98.00%, 98.00%, 98.00%\n",
      "step: 18650 \ttraining acc: 19.58%, 96.71%, 97.83%, 97.88%, 97.88%, 97.92%\n",
      "step: 18700 \ttraining acc: 21.50%, 97.38%, 98.62%, 98.67%, 98.75%, 98.75%\n",
      "step: 18750 \ttraining acc: 20.54%, 97.00%, 97.46%, 97.46%, 97.54%, 97.58%\n",
      "step: 18800 \ttraining acc: 20.79%, 97.08%, 97.33%, 97.42%, 97.50%, 97.54%\n",
      "step: 18850 \ttraining acc: 15.38%, 97.38%, 98.17%, 98.17%, 98.17%, 98.21%\n",
      "step: 18900 \ttraining acc: 25.71%, 98.62%, 98.83%, 98.83%, 98.83%, 98.83%\n",
      "step: 18950 \ttraining acc: 17.58%, 97.00%, 97.92%, 97.92%, 97.96%, 98.04%\n",
      "step: 19000 \ttraining acc: 19.71%, 96.25%, 97.96%, 97.96%, 97.96%, 98.00%\n",
      "Test acc: [0.1995 0.904  0.917  0.918  0.9185 0.9185 0.919  0.919  0.9194 0.9194\n",
      " 0.92  ]\n",
      "step: 19050 \ttraining acc: 21.46%, 97.67%, 98.29%, 98.42%, 98.42%, 98.38%\n",
      "step: 19100 \ttraining acc: 18.04%, 97.62%, 98.25%, 98.25%, 98.25%, 98.21%\n",
      "step: 19150 \ttraining acc: 17.67%, 94.33%, 96.71%, 96.75%, 96.79%, 96.88%\n",
      "step: 19200 \ttraining acc: 24.17%, 96.12%, 97.79%, 97.88%, 97.88%, 97.92%\n",
      "step: 19250 \ttraining acc: 21.88%, 95.67%, 97.54%, 97.67%, 97.67%, 97.62%\n",
      "step: 19300 \ttraining acc: 18.96%, 96.54%, 97.00%, 97.04%, 97.12%, 97.17%\n",
      "step: 19350 \ttraining acc: 20.75%, 96.21%, 97.08%, 97.08%, 97.08%, 97.21%\n",
      "step: 19400 \ttraining acc: 23.50%, 97.00%, 97.17%, 97.17%, 97.17%, 97.21%\n",
      "step: 19450 \ttraining acc: 18.79%, 95.92%, 97.00%, 97.21%, 97.21%, 97.12%\n",
      "step: 19500 \ttraining acc: 20.83%, 96.38%, 97.38%, 97.33%, 97.33%, 97.42%\n",
      "Test acc: [0.2059 0.909  0.921  0.9214 0.922  0.922  0.9224 0.9224 0.923  0.9233\n",
      " 0.9233]\n",
      "step: 19550 \ttraining acc: 18.17%, 96.33%, 97.83%, 97.83%, 97.92%, 97.92%\n",
      "step: 19600 \ttraining acc: 17.17%, 96.04%, 96.96%, 97.12%, 97.12%, 97.17%\n",
      "step: 19650 \ttraining acc: 25.50%, 97.54%, 97.92%, 97.92%, 97.92%, 97.96%\n",
      "step: 19700 \ttraining acc: 17.67%, 96.96%, 98.08%, 98.08%, 98.12%, 98.12%\n",
      "step: 19750 \ttraining acc: 20.58%, 96.67%, 97.58%, 97.62%, 97.71%, 97.79%\n",
      "step: 19800 \ttraining acc: 19.50%, 97.83%, 98.71%, 98.75%, 98.75%, 98.79%\n",
      "step: 19850 \ttraining acc: 18.75%, 97.71%, 97.79%, 97.79%, 97.75%, 97.79%\n",
      "step: 19900 \ttraining acc: 21.96%, 98.08%, 98.04%, 98.08%, 98.08%, 98.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 19950 \ttraining acc: 20.33%, 96.92%, 97.25%, 97.29%, 97.29%, 97.38%\n",
      "step: 20000 \ttraining acc: 24.08%, 96.04%, 97.25%, 97.33%, 97.38%, 97.42%\n",
      "Test acc: [0.202  0.9077 0.918  0.9185 0.919  0.919  0.9194 0.9194 0.9194 0.92\n",
      " 0.92  ]\n",
      "step: 20050 \ttraining acc: 18.08%, 96.75%, 97.79%, 97.83%, 97.88%, 97.88%\n",
      "step: 20100 \ttraining acc: 22.92%, 97.96%, 98.29%, 98.33%, 98.46%, 98.46%\n",
      "step: 20150 \ttraining acc: 18.92%, 97.92%, 98.25%, 98.25%, 98.25%, 98.25%\n",
      "step: 20200 \ttraining acc: 18.75%, 97.12%, 98.04%, 98.12%, 98.17%, 98.21%\n",
      "step: 20250 \ttraining acc: 21.17%, 98.58%, 98.54%, 98.58%, 98.62%, 98.62%\n",
      "step: 20300 \ttraining acc: 24.12%, 96.42%, 97.83%, 97.92%, 97.92%, 97.88%\n",
      "step: 20350 \ttraining acc: 21.29%, 96.38%, 97.17%, 97.17%, 97.17%, 97.17%\n",
      "step: 20400 \ttraining acc: 22.62%, 97.62%, 98.12%, 98.12%, 98.12%, 98.12%\n",
      "step: 20450 \ttraining acc: 16.04%, 97.29%, 98.21%, 98.21%, 98.25%, 98.25%\n",
      "step: 20500 \ttraining acc: 19.29%, 98.25%, 98.38%, 98.38%, 98.42%, 98.42%\n",
      "Test acc: [0.1992 0.915  0.9243 0.925  0.9253 0.9253 0.926  0.926  0.9263 0.9263\n",
      " 0.9263]\n",
      "step: 20550 \ttraining acc: 22.08%, 96.42%, 97.50%, 97.54%, 97.54%, 97.54%\n",
      "step: 20600 \ttraining acc: 18.62%, 96.08%, 97.17%, 97.21%, 97.21%, 97.21%\n",
      "step: 20650 \ttraining acc: 18.25%, 96.62%, 97.00%, 97.04%, 97.04%, 97.04%\n",
      "step: 20700 \ttraining acc: 19.21%, 97.67%, 98.21%, 98.21%, 98.21%, 98.21%\n",
      "step: 20750 \ttraining acc: 21.42%, 97.17%, 97.96%, 98.00%, 98.00%, 98.04%\n",
      "step: 20800 \ttraining acc: 19.25%, 96.75%, 97.50%, 97.54%, 97.58%, 97.67%\n",
      "step: 20850 \ttraining acc: 25.04%, 97.17%, 97.92%, 98.00%, 98.00%, 98.00%\n",
      "step: 20900 \ttraining acc: 19.12%, 98.00%, 98.33%, 98.38%, 98.38%, 98.38%\n",
      "step: 20950 \ttraining acc: 18.29%, 95.71%, 97.21%, 97.21%, 97.21%, 97.25%\n",
      "step: 21000 \ttraining acc: 18.25%, 97.75%, 98.33%, 98.38%, 98.38%, 98.38%\n",
      "Test acc: [0.1962 0.9126 0.923  0.9233 0.924  0.9243 0.9243 0.925  0.925  0.925\n",
      " 0.9253]\n",
      "step: 21050 \ttraining acc: 19.00%, 96.54%, 97.33%, 97.33%, 97.33%, 97.33%\n",
      "step: 21100 \ttraining acc: 18.71%, 97.25%, 98.04%, 98.17%, 98.17%, 98.21%\n",
      "step: 21150 \ttraining acc: 25.67%, 97.46%, 97.71%, 97.71%, 97.71%, 97.71%\n",
      "step: 21200 \ttraining acc: 22.00%, 97.83%, 98.25%, 98.25%, 98.29%, 98.29%\n",
      "step: 21250 \ttraining acc: 17.29%, 98.46%, 98.96%, 98.96%, 98.96%, 98.96%\n",
      "step: 21300 \ttraining acc: 13.08%, 96.25%, 96.58%, 96.71%, 96.75%, 96.79%\n",
      "step: 21350 \ttraining acc: 20.67%, 97.38%, 97.88%, 97.92%, 97.92%, 97.96%\n",
      "step: 21400 \ttraining acc: 20.79%, 97.12%, 98.12%, 98.17%, 98.17%, 98.17%\n",
      "step: 21450 \ttraining acc: 22.46%, 97.38%, 98.17%, 98.46%, 98.54%, 98.54%\n",
      "step: 21500 \ttraining acc: 20.79%, 97.88%, 98.17%, 98.21%, 98.25%, 98.25%\n",
      "Test acc: [0.2007 0.9126 0.924  0.9243 0.9243 0.925  0.925  0.9253 0.9253 0.926\n",
      " 0.926 ]\n",
      "step: 21550 \ttraining acc: 18.62%, 98.75%, 98.83%, 98.92%, 98.92%, 98.96%\n",
      "step: 21600 \ttraining acc: 15.21%, 97.29%, 98.04%, 98.04%, 98.04%, 98.04%\n",
      "step: 21650 \ttraining acc: 22.46%, 97.17%, 97.75%, 97.79%, 97.79%, 97.79%\n",
      "step: 21700 \ttraining acc: 23.00%, 96.54%, 97.04%, 97.08%, 97.12%, 97.17%\n",
      "step: 21750 \ttraining acc: 17.50%, 97.12%, 97.58%, 97.67%, 97.71%, 97.75%\n",
      "step: 21800 \ttraining acc: 20.92%, 95.88%, 96.88%, 96.96%, 97.00%, 97.00%\n",
      "step: 21850 \ttraining acc: 20.42%, 97.29%, 98.17%, 98.17%, 98.21%, 98.21%\n",
      "step: 21900 \ttraining acc: 18.38%, 97.42%, 97.92%, 98.00%, 98.00%, 98.00%\n",
      "step: 21950 \ttraining acc: 21.17%, 96.79%, 98.04%, 98.04%, 98.04%, 98.08%\n",
      "step: 22000 \ttraining acc: 18.42%, 97.50%, 98.92%, 98.92%, 98.96%, 98.96%\n",
      "Test acc: [0.2    0.914  0.9224 0.923  0.9233 0.924  0.9243 0.9243 0.925  0.925\n",
      " 0.925 ]\n",
      "step: 22050 \ttraining acc: 21.04%, 97.67%, 98.25%, 98.25%, 98.33%, 98.33%\n",
      "step: 22100 \ttraining acc: 20.50%, 95.62%, 97.42%, 97.42%, 97.46%, 97.46%\n",
      "step: 22150 \ttraining acc: 16.17%, 97.25%, 98.21%, 98.25%, 98.29%, 98.29%\n",
      "step: 22200 \ttraining acc: 18.21%, 95.92%, 97.92%, 97.92%, 97.92%, 97.92%\n",
      "step: 22250 \ttraining acc: 17.12%, 97.25%, 97.75%, 97.79%, 97.83%, 97.88%\n",
      "step: 22300 \ttraining acc: 19.88%, 96.88%, 97.79%, 97.83%, 97.92%, 97.92%\n",
      "step: 22350 \ttraining acc: 16.00%, 97.71%, 97.75%, 97.75%, 97.75%, 97.75%\n",
      "step: 22400 \ttraining acc: 20.29%, 97.46%, 98.17%, 98.21%, 98.21%, 98.25%\n",
      "step: 22450 \ttraining acc: 20.25%, 97.42%, 98.12%, 98.12%, 98.17%, 98.17%\n",
      "step: 22500 \ttraining acc: 24.25%, 96.62%, 97.17%, 97.17%, 97.21%, 97.21%\n",
      "Test acc: [0.1979 0.915  0.9243 0.925  0.9253 0.9253 0.926  0.926  0.926  0.9263\n",
      " 0.9263]\n",
      "step: 22550 \ttraining acc: 24.42%, 98.21%, 98.58%, 98.67%, 98.67%, 98.67%\n",
      "step: 22600 \ttraining acc: 18.58%, 97.04%, 97.67%, 97.67%, 97.67%, 97.67%\n",
      "step: 22650 \ttraining acc: 22.58%, 97.46%, 97.67%, 97.67%, 97.75%, 97.79%\n",
      "step: 22700 \ttraining acc: 21.71%, 98.83%, 98.92%, 98.96%, 98.96%, 98.96%\n",
      "step: 22750 \ttraining acc: 21.50%, 95.21%, 97.17%, 97.21%, 97.21%, 97.25%\n",
      "step: 22800 \ttraining acc: 22.17%, 96.21%, 97.21%, 97.25%, 97.29%, 97.29%\n",
      "step: 22850 \ttraining acc: 23.79%, 97.62%, 98.12%, 98.12%, 98.17%, 98.12%\n",
      "step: 22900 \ttraining acc: 20.54%, 96.25%, 96.79%, 96.83%, 96.88%, 96.92%\n",
      "step: 22950 \ttraining acc: 20.46%, 97.58%, 98.29%, 98.33%, 98.33%, 98.33%\n",
      "step: 23000 \ttraining acc: 20.17%, 97.62%, 97.92%, 97.92%, 97.92%, 97.92%\n",
      "Test acc: [0.1984 0.913  0.921  0.9214 0.9214 0.922  0.9224 0.9224 0.9224 0.923\n",
      " 0.923 ]\n",
      "step: 23050 \ttraining acc: 19.54%, 97.00%, 97.83%, 97.83%, 97.88%, 97.88%\n",
      "step: 23100 \ttraining acc: 19.33%, 96.08%, 96.83%, 96.88%, 96.96%, 96.96%\n",
      "step: 23150 \ttraining acc: 20.58%, 96.25%, 98.54%, 98.58%, 98.62%, 98.62%\n",
      "step: 23200 \ttraining acc: 13.50%, 98.38%, 98.79%, 98.79%, 98.83%, 98.88%\n",
      "step: 23250 \ttraining acc: 20.79%, 97.96%, 98.58%, 98.58%, 98.67%, 98.71%\n",
      "step: 23300 \ttraining acc: 21.12%, 96.25%, 96.96%, 97.00%, 97.08%, 97.12%\n",
      "step: 23350 \ttraining acc: 17.58%, 96.88%, 97.12%, 97.12%, 97.12%, 97.21%\n",
      "step: 23400 \ttraining acc: 22.25%, 98.04%, 99.08%, 99.08%, 99.08%, 99.08%\n",
      "step: 23450 \ttraining acc: 23.04%, 97.92%, 98.79%, 98.83%, 98.83%, 98.83%\n",
      "step: 23500 \ttraining acc: 25.33%, 95.92%, 96.96%, 97.00%, 97.08%, 97.12%\n",
      "Test acc: [0.202  0.917  0.925  0.9253 0.9253 0.926  0.926  0.9263 0.9263 0.9263\n",
      " 0.927 ]\n",
      "step: 23550 \ttraining acc: 18.79%, 97.25%, 97.96%, 98.00%, 98.00%, 98.04%\n",
      "step: 23600 \ttraining acc: 17.38%, 96.46%, 97.50%, 97.50%, 97.50%, 97.50%\n",
      "step: 23650 \ttraining acc: 21.92%, 97.17%, 97.96%, 97.96%, 98.00%, 98.04%\n",
      "step: 23700 \ttraining acc: 23.96%, 97.12%, 98.58%, 98.58%, 98.58%, 98.58%\n",
      "step: 23750 \ttraining acc: 19.88%, 97.96%, 98.00%, 98.04%, 98.04%, 98.04%\n",
      "step: 23800 \ttraining acc: 20.58%, 97.42%, 97.71%, 97.71%, 97.79%, 97.79%\n",
      "step: 23850 \ttraining acc: 18.17%, 96.96%, 97.58%, 97.62%, 97.62%, 97.62%\n",
      "step: 23900 \ttraining acc: 22.17%, 97.04%, 97.83%, 97.88%, 97.88%, 97.88%\n",
      "step: 23950 \ttraining acc: 22.75%, 97.17%, 98.79%, 98.83%, 98.88%, 98.88%\n",
      "step: 24000 \ttraining acc: 21.79%, 96.12%, 97.21%, 97.25%, 97.25%, 97.38%\n",
      "Test acc: [0.1991 0.917  0.926  0.9263 0.9263 0.927  0.927  0.9272 0.9272 0.9272\n",
      " 0.9277]\n",
      "step: 24050 \ttraining acc: 18.00%, 98.12%, 98.58%, 98.58%, 98.62%, 98.67%\n",
      "step: 24100 \ttraining acc: 21.62%, 97.33%, 97.83%, 97.83%, 97.83%, 97.83%\n",
      "step: 24150 \ttraining acc: 18.38%, 98.29%, 98.67%, 98.67%, 98.67%, 98.62%\n",
      "step: 24200 \ttraining acc: 20.50%, 95.25%, 96.08%, 96.17%, 96.21%, 96.29%\n",
      "step: 24250 \ttraining acc: 18.50%, 98.46%, 98.62%, 98.62%, 98.54%, 98.58%\n",
      "step: 24300 \ttraining acc: 18.04%, 97.92%, 98.08%, 98.12%, 98.12%, 98.17%\n",
      "step: 24350 \ttraining acc: 22.58%, 96.33%, 96.50%, 96.88%, 96.88%, 96.88%\n",
      "step: 24400 \ttraining acc: 23.96%, 96.83%, 97.83%, 97.83%, 97.83%, 97.88%\n",
      "step: 24450 \ttraining acc: 16.29%, 97.50%, 97.62%, 97.71%, 97.75%, 97.83%\n",
      "step: 24500 \ttraining acc: 19.21%, 97.71%, 98.29%, 98.33%, 98.33%, 98.38%\n",
      "Test acc: [0.2015 0.9204 0.927  0.9272 0.9277 0.928  0.928  0.9287 0.9287 0.9287\n",
      " 0.9287]\n",
      "step: 24550 \ttraining acc: 15.83%, 98.25%, 98.67%, 98.67%, 98.71%, 98.71%\n",
      "step: 24600 \ttraining acc: 20.62%, 98.08%, 98.50%, 98.54%, 98.54%, 98.54%\n",
      "step: 24650 \ttraining acc: 20.79%, 96.92%, 97.17%, 97.17%, 97.21%, 97.25%\n",
      "step: 24700 \ttraining acc: 18.42%, 97.33%, 98.29%, 98.33%, 98.38%, 98.42%\n",
      "step: 24750 \ttraining acc: 18.04%, 97.38%, 97.83%, 97.83%, 97.83%, 97.83%\n",
      "step: 24800 \ttraining acc: 22.50%, 97.29%, 97.71%, 97.71%, 97.71%, 97.75%\n",
      "step: 24850 \ttraining acc: 20.83%, 95.79%, 96.54%, 96.54%, 96.54%, 96.54%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 24900 \ttraining acc: 17.83%, 96.46%, 97.79%, 97.79%, 97.88%, 97.88%\n",
      "step: 24950 \ttraining acc: 25.42%, 97.42%, 98.33%, 98.38%, 98.42%, 98.50%\n",
      "step: 25000 \ttraining acc: 19.38%, 96.79%, 96.92%, 96.92%, 96.92%, 96.92%\n",
      "Test acc: [0.2004 0.915  0.922  0.9224 0.9224 0.923  0.923  0.9233 0.9233 0.9233\n",
      " 0.924 ]\n",
      "step: 25050 \ttraining acc: 21.42%, 97.58%, 98.00%, 98.04%, 98.08%, 98.08%\n",
      "step: 25100 \ttraining acc: 18.38%, 97.54%, 98.21%, 98.21%, 98.25%, 98.29%\n",
      "step: 25150 \ttraining acc: 24.00%, 97.12%, 98.21%, 98.38%, 98.38%, 98.38%\n",
      "step: 25200 \ttraining acc: 20.17%, 96.75%, 98.08%, 98.12%, 98.12%, 98.12%\n",
      "step: 25250 \ttraining acc: 18.67%, 97.12%, 97.17%, 97.25%, 97.21%, 97.21%\n",
      "step: 25300 \ttraining acc: 21.29%, 97.50%, 98.25%, 98.25%, 98.29%, 98.29%\n",
      "step: 25350 \ttraining acc: 18.38%, 97.04%, 97.96%, 98.04%, 98.04%, 98.04%\n",
      "step: 25400 \ttraining acc: 19.54%, 98.83%, 99.08%, 99.17%, 99.17%, 99.17%\n",
      "step: 25450 \ttraining acc: 16.75%, 98.12%, 98.42%, 98.46%, 98.50%, 98.50%\n",
      "step: 25500 \ttraining acc: 17.38%, 98.33%, 98.92%, 98.92%, 98.92%, 98.92%\n",
      "Test acc: [0.2    0.914  0.92   0.9204 0.921  0.921  0.9214 0.9214 0.9214 0.922\n",
      " 0.922 ]\n",
      "step: 25550 \ttraining acc: 25.75%, 96.12%, 96.46%, 96.54%, 96.54%, 96.58%\n",
      "step: 25600 \ttraining acc: 20.38%, 98.33%, 98.83%, 98.96%, 99.00%, 99.04%\n",
      "step: 25650 \ttraining acc: 16.92%, 98.38%, 99.12%, 99.17%, 99.21%, 99.21%\n",
      "step: 25700 \ttraining acc: 17.88%, 98.04%, 98.00%, 98.00%, 98.04%, 98.04%\n",
      "step: 25750 \ttraining acc: 17.54%, 97.79%, 98.33%, 98.33%, 98.38%, 98.38%\n",
      "step: 25800 \ttraining acc: 21.79%, 97.54%, 98.50%, 98.54%, 98.54%, 98.58%\n",
      "step: 25850 \ttraining acc: 19.46%, 98.46%, 98.83%, 98.88%, 98.88%, 98.92%\n",
      "step: 25900 \ttraining acc: 21.42%, 97.54%, 98.00%, 98.08%, 98.12%, 98.17%\n",
      "step: 25950 \ttraining acc: 19.25%, 98.00%, 98.46%, 98.46%, 98.50%, 98.50%\n",
      "step: 26000 \ttraining acc: 18.17%, 97.00%, 98.33%, 98.33%, 98.33%, 98.38%\n",
      "Test acc: [0.2042 0.9185 0.926  0.9263 0.927  0.927  0.9272 0.9272 0.9272 0.9272\n",
      " 0.9277]\n",
      "step: 26050 \ttraining acc: 18.71%, 97.04%, 97.62%, 97.67%, 97.67%, 97.71%\n",
      "step: 26100 \ttraining acc: 19.79%, 97.96%, 98.83%, 98.88%, 98.92%, 98.92%\n",
      "step: 26150 \ttraining acc: 16.79%, 96.92%, 98.17%, 98.38%, 98.38%, 98.38%\n",
      "step: 26200 \ttraining acc: 23.83%, 98.58%, 99.04%, 99.04%, 99.04%, 99.04%\n",
      "step: 26250 \ttraining acc: 21.04%, 97.88%, 98.00%, 98.00%, 98.04%, 98.04%\n",
      "step: 26300 \ttraining acc: 22.25%, 98.21%, 98.62%, 98.62%, 98.62%, 98.62%\n",
      "step: 26350 \ttraining acc: 18.79%, 97.92%, 98.46%, 98.50%, 98.50%, 98.50%\n",
      "step: 26400 \ttraining acc: 19.96%, 97.62%, 98.25%, 98.25%, 98.25%, 98.29%\n",
      "step: 26450 \ttraining acc: 18.96%, 98.04%, 98.67%, 98.71%, 98.75%, 98.75%\n",
      "step: 26500 \ttraining acc: 20.96%, 97.75%, 98.12%, 98.25%, 98.33%, 98.33%\n",
      "Test acc: [0.203  0.917  0.923  0.9233 0.9233 0.924  0.9243 0.9243 0.9243 0.925\n",
      " 0.925 ]\n",
      "step: 26550 \ttraining acc: 16.42%, 96.62%, 97.54%, 97.54%, 97.58%, 97.54%\n",
      "step: 26600 \ttraining acc: 17.04%, 96.92%, 97.42%, 97.46%, 97.50%, 97.54%\n",
      "step: 26650 \ttraining acc: 21.29%, 97.29%, 98.29%, 98.29%, 98.25%, 98.29%\n",
      "step: 26700 \ttraining acc: 22.21%, 97.21%, 98.17%, 98.21%, 98.21%, 98.21%\n",
      "step: 26750 \ttraining acc: 17.62%, 97.83%, 97.96%, 98.00%, 98.04%, 98.04%\n",
      "step: 26800 \ttraining acc: 17.79%, 97.58%, 97.79%, 97.79%, 97.83%, 97.83%\n",
      "step: 26850 \ttraining acc: 24.04%, 98.12%, 98.50%, 98.50%, 98.50%, 98.50%\n",
      "step: 26900 \ttraining acc: 18.79%, 96.88%, 97.12%, 97.12%, 97.17%, 97.21%\n",
      "step: 26950 \ttraining acc: 22.08%, 98.08%, 98.62%, 98.62%, 98.71%, 98.75%\n",
      "step: 27000 \ttraining acc: 19.79%, 97.83%, 97.92%, 98.00%, 98.00%, 98.00%\n",
      "Test acc: [0.2043 0.9194 0.926  0.926  0.9263 0.927  0.927  0.927  0.9272 0.9272\n",
      " 0.9277]\n",
      "step: 27050 \ttraining acc: 17.71%, 98.17%, 98.33%, 98.33%, 98.33%, 98.38%\n",
      "step: 27100 \ttraining acc: 16.83%, 97.62%, 98.54%, 98.54%, 98.54%, 98.54%\n",
      "step: 27150 \ttraining acc: 20.33%, 97.42%, 98.62%, 98.62%, 98.62%, 98.67%\n",
      "step: 27200 \ttraining acc: 20.46%, 97.75%, 97.92%, 97.92%, 97.92%, 97.92%\n",
      "step: 27250 \ttraining acc: 23.00%, 97.58%, 97.88%, 97.92%, 97.92%, 97.92%\n",
      "step: 27300 \ttraining acc: 21.62%, 97.00%, 97.79%, 97.92%, 97.92%, 98.00%\n",
      "step: 27350 \ttraining acc: 20.04%, 96.83%, 97.08%, 97.21%, 97.25%, 97.29%\n",
      "step: 27400 \ttraining acc: 21.67%, 98.29%, 99.21%, 99.21%, 99.21%, 99.25%\n",
      "step: 27450 \ttraining acc: 18.67%, 98.00%, 98.54%, 98.54%, 98.58%, 98.62%\n",
      "step: 27500 \ttraining acc: 13.25%, 96.75%, 97.38%, 97.42%, 97.46%, 97.46%\n",
      "Test acc: [0.1962 0.917  0.925  0.9253 0.926  0.926  0.926  0.9263 0.9263 0.9263\n",
      " 0.927 ]\n",
      "step: 27550 \ttraining acc: 16.33%, 97.46%, 97.71%, 97.71%, 97.71%, 97.71%\n",
      "step: 27600 \ttraining acc: 18.67%, 98.46%, 98.88%, 98.88%, 98.88%, 98.92%\n",
      "step: 27650 \ttraining acc: 15.50%, 98.21%, 98.50%, 98.46%, 98.46%, 98.46%\n",
      "step: 27700 \ttraining acc: 16.25%, 98.50%, 98.88%, 98.92%, 98.92%, 98.92%\n",
      "step: 27750 \ttraining acc: 24.17%, 97.92%, 98.25%, 98.25%, 98.25%, 98.25%\n",
      "step: 27800 \ttraining acc: 21.25%, 98.17%, 98.62%, 98.62%, 98.62%, 98.62%\n",
      "step: 27850 \ttraining acc: 19.17%, 97.17%, 97.88%, 97.88%, 97.88%, 97.96%\n",
      "step: 27900 \ttraining acc: 21.04%, 97.12%, 97.46%, 97.50%, 97.46%, 97.46%\n",
      "step: 27950 \ttraining acc: 20.75%, 98.17%, 98.67%, 98.67%, 98.67%, 98.67%\n",
      "step: 28000 \ttraining acc: 16.71%, 97.92%, 98.33%, 98.25%, 98.29%, 98.33%\n",
      "Test acc: [0.1974 0.92   0.9253 0.9253 0.926  0.9263 0.9263 0.9263 0.927  0.927\n",
      " 0.927 ]\n",
      "step: 28050 \ttraining acc: 18.62%, 97.29%, 98.17%, 98.17%, 98.17%, 98.17%\n",
      "step: 28100 \ttraining acc: 14.42%, 97.50%, 98.12%, 98.12%, 98.21%, 98.25%\n",
      "step: 28150 \ttraining acc: 22.38%, 97.62%, 97.83%, 97.92%, 97.96%, 97.96%\n",
      "step: 28200 \ttraining acc: 22.33%, 96.92%, 98.17%, 98.21%, 98.21%, 98.25%\n",
      "step: 28250 \ttraining acc: 19.62%, 97.12%, 97.96%, 97.96%, 97.96%, 97.96%\n",
      "step: 28300 \ttraining acc: 17.25%, 98.38%, 98.75%, 98.83%, 98.83%, 98.83%\n",
      "step: 28350 \ttraining acc: 18.58%, 97.71%, 98.25%, 98.29%, 98.29%, 98.29%\n",
      "step: 28400 \ttraining acc: 22.79%, 95.75%, 97.08%, 97.04%, 97.04%, 97.08%\n",
      "step: 28450 \ttraining acc: 18.04%, 97.21%, 97.88%, 98.04%, 98.12%, 98.17%\n",
      "step: 28500 \ttraining acc: 20.92%, 98.67%, 98.83%, 98.92%, 98.92%, 98.92%\n",
      "Test acc: [0.203  0.9165 0.9224 0.9233 0.9233 0.924  0.924  0.9243 0.9243 0.9243\n",
      " 0.9243]\n",
      "step: 28550 \ttraining acc: 22.58%, 97.00%, 97.12%, 97.12%, 97.17%, 97.21%\n",
      "step: 28600 \ttraining acc: 23.83%, 98.67%, 98.96%, 98.96%, 99.00%, 99.00%\n",
      "step: 28650 \ttraining acc: 20.96%, 98.17%, 98.58%, 98.62%, 98.71%, 98.71%\n",
      "step: 28700 \ttraining acc: 20.46%, 98.62%, 98.83%, 98.83%, 98.92%, 98.92%\n",
      "step: 28750 \ttraining acc: 15.38%, 97.83%, 98.38%, 98.38%, 98.54%, 98.58%\n",
      "step: 28800 \ttraining acc: 15.21%, 97.62%, 98.00%, 98.00%, 98.00%, 98.00%\n",
      "step: 28850 \ttraining acc: 20.29%, 97.75%, 98.00%, 98.04%, 98.04%, 98.04%\n",
      "step: 28900 \ttraining acc: 17.33%, 97.33%, 98.04%, 98.08%, 98.08%, 98.08%\n",
      "step: 28950 \ttraining acc: 17.38%, 96.92%, 97.46%, 97.50%, 97.50%, 97.58%\n",
      "step: 29000 \ttraining acc: 19.71%, 96.83%, 97.67%, 97.75%, 97.79%, 97.92%\n",
      "Test acc: [0.1957 0.922  0.928  0.928  0.9287 0.9287 0.9287 0.929  0.929  0.929\n",
      " 0.9297]\n",
      "step: 29050 \ttraining acc: 20.62%, 97.88%, 98.71%, 98.75%, 98.75%, 98.79%\n",
      "step: 29100 \ttraining acc: 19.33%, 97.17%, 97.29%, 97.38%, 97.42%, 97.42%\n",
      "step: 29150 \ttraining acc: 21.96%, 97.54%, 98.12%, 98.17%, 98.21%, 98.25%\n",
      "step: 29200 \ttraining acc: 19.17%, 97.79%, 98.25%, 98.25%, 98.25%, 98.25%\n",
      "step: 29250 \ttraining acc: 23.96%, 97.46%, 97.88%, 97.88%, 97.88%, 97.88%\n",
      "step: 29300 \ttraining acc: 25.62%, 98.33%, 99.04%, 99.08%, 99.12%, 99.12%\n",
      "step: 29350 \ttraining acc: 20.75%, 96.83%, 97.58%, 97.58%, 97.58%, 97.58%\n",
      "step: 29400 \ttraining acc: 18.79%, 96.79%, 96.96%, 97.00%, 97.04%, 97.12%\n",
      "step: 29450 \ttraining acc: 15.71%, 97.83%, 98.79%, 98.79%, 98.79%, 98.79%\n",
      "step: 29500 \ttraining acc: 18.17%, 97.67%, 98.50%, 98.54%, 98.58%, 98.62%\n",
      "Test acc: [0.1926 0.915  0.921  0.922  0.922  0.922  0.9224 0.9224 0.9224 0.923\n",
      " 0.923 ]\n",
      "step: 29550 \ttraining acc: 21.58%, 97.00%, 97.12%, 97.17%, 97.17%, 97.21%\n",
      "step: 29600 \ttraining acc: 21.12%, 97.75%, 98.08%, 98.12%, 98.12%, 98.12%\n",
      "step: 29650 \ttraining acc: 16.21%, 97.33%, 97.71%, 97.71%, 97.71%, 97.75%\n",
      "step: 29700 \ttraining acc: 22.75%, 97.67%, 98.12%, 98.12%, 98.12%, 98.12%\n",
      "step: 29750 \ttraining acc: 21.29%, 97.75%, 98.46%, 98.54%, 98.58%, 98.58%\n",
      "step: 29800 \ttraining acc: 21.12%, 97.96%, 98.46%, 98.46%, 98.46%, 98.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 29850 \ttraining acc: 20.12%, 97.46%, 98.38%, 98.42%, 98.42%, 98.42%\n",
      "step: 29900 \ttraining acc: 17.62%, 97.54%, 98.00%, 98.00%, 98.04%, 98.04%\n",
      "step: 29950 \ttraining acc: 21.75%, 98.67%, 98.08%, 98.29%, 98.33%, 98.33%\n",
      "step: 30000 \ttraining acc: 18.75%, 98.79%, 99.12%, 99.12%, 99.12%, 99.12%\n",
      "Test acc: [0.2039 0.9204 0.9277 0.928  0.928  0.9287 0.9287 0.9287 0.9287 0.929\n",
      " 0.929 ]\n",
      "step: 30050 \ttraining acc: 20.62%, 97.46%, 98.12%, 98.17%, 98.21%, 98.21%\n",
      "step: 30100 \ttraining acc: 22.25%, 98.17%, 98.62%, 98.58%, 98.67%, 98.67%\n",
      "step: 30150 \ttraining acc: 18.83%, 98.29%, 98.62%, 98.62%, 98.62%, 98.67%\n",
      "step: 30200 \ttraining acc: 18.62%, 98.62%, 99.04%, 99.08%, 99.08%, 99.12%\n",
      "step: 30250 \ttraining acc: 22.33%, 98.29%, 98.96%, 98.96%, 98.96%, 98.96%\n",
      "step: 30300 \ttraining acc: 23.42%, 97.71%, 98.17%, 98.29%, 98.29%, 98.29%\n",
      "step: 30350 \ttraining acc: 21.50%, 97.67%, 98.46%, 98.46%, 98.54%, 98.54%\n",
      "step: 30400 \ttraining acc: 19.75%, 98.00%, 98.29%, 98.29%, 98.29%, 98.29%\n",
      "step: 30450 \ttraining acc: 23.62%, 98.42%, 98.42%, 98.42%, 98.46%, 98.50%\n",
      "step: 30500 \ttraining acc: 23.46%, 98.17%, 98.46%, 98.46%, 98.50%, 98.50%\n",
      "Test acc: [0.1976 0.918  0.923  0.9233 0.924  0.924  0.924  0.9243 0.9243 0.9243\n",
      " 0.925 ]\n",
      "step: 30550 \ttraining acc: 19.12%, 98.21%, 98.62%, 98.62%, 98.67%, 98.67%\n",
      "step: 30600 \ttraining acc: 21.00%, 96.75%, 97.08%, 97.12%, 97.17%, 97.21%\n",
      "step: 30650 \ttraining acc: 16.42%, 97.88%, 98.12%, 98.12%, 98.12%, 98.12%\n"
     ]
    }
   ],
   "source": [
    "for step in range(args.epoch):\n",
    "\n",
    "    x_spt, y_spt, x_qry, y_qry = db_train.next()\n",
    "    x_spt, y_spt, x_qry, y_qry = (\n",
    "        torch.from_numpy(x_spt).to(device), \n",
    "        torch.from_numpy(y_spt).to(device).long(),\n",
    "        torch.from_numpy(x_qry).to(device), \n",
    "        torch.from_numpy(y_qry).to(device).long()\n",
    "    )\n",
    "\n",
    "    # set traning=True to update running_mean, running_variance, bn_weights, bn_bias\n",
    "    accs = maml(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "    if step % 50 == 0:\n",
    "        string = ', '.join([f\"{a:2.2%}\" for a in accs])\n",
    "        print('step:', step, f'\\ttraining acc: {string}')\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        accs = []\n",
    "        for _ in range(1000//args.task_num):\n",
    "            # test\n",
    "            x_spt, y_spt, x_qry, y_qry = db_train.next('test')\n",
    "            x_spt, y_spt, x_qry, y_qry = (\n",
    "                torch.from_numpy(x_spt).to(device), \n",
    "                torch.from_numpy(y_spt).to(device).long(),\n",
    "                torch.from_numpy(x_qry).to(device), \n",
    "                torch.from_numpy(y_qry).to(device).long()\n",
    "            )\n",
    "\n",
    "            # split to single task each time\n",
    "            for x_spt_one, y_spt_one, x_qry_one, y_qry_one in zip(x_spt, y_spt, x_qry, y_qry):\n",
    "                test_acc = maml.finetunning(x_spt_one, y_spt_one, x_qry_one, y_qry_one)\n",
    "                accs.append( test_acc )\n",
    "\n",
    "        # [b, update_step+1]\n",
    "        accs = np.array(accs).mean(axis=0).astype(np.float16)\n",
    "        print('Test acc:', accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "basic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
